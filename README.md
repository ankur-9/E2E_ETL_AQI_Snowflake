# E2E_ETL_AQI_Snowflake

ğŸŒ Real-Time India Air Quality Index (AQI) â€“ End-to-End Snowflake Data Engineering Project

ğŸ“˜ Project Overview
This project showcases an end-to-end real-time data engineering pipeline built on Snowflake, leveraging Dynamic Tables for continuous data transformation and Streamlit for interactive visualization. The system processes Indiaâ€™s real-time Air Quality Index (AQI) data from the Government of India Open Data Platform, updates it hourly, and provides city and station-level AQI insights.


ğŸ§  Objective
To design a fully automated, scalable, and near real-time data pipeline that:
Ingests and processes AQI data every hour.
Cleans and transforms nested JSON data efficiently using Snowflake Dynamic Tables.
Computes AQI metrics and aggregates them at city and day levels.
Provides live insights through a Streamlit dashboard.
Uses GitHub Actions for automated hourly ingestion scheduling.


ğŸ—ï¸ Architecture Overview
1ï¸âƒ£ Data Source:
Real-Time AQI API â€” provides hourly pollutant readings from multiple monitoring stations across Indian cities.

2ï¸âƒ£ Ingestion Layer:
Python script connects to the API and loads raw JSON data to Snowflake Internal Stage.
A Snowflake Task copies staged data into a raw table in dev_db.stage_schema.

3ï¸âƒ£ Transformation Layer (Dynamic Tables):
Clean Schema:
Dynamic tables parse and flatten JSON data where:
1 State â†’ Multiple Cities
1 City â†’ Multiple Stations
1 Station â†’ 7 Pollutants (each with min, max, avg values)
Cleaned data stored at hourly granularity.
Consumption Schema:
Dynamic tables calculate AQI based on pollutant readings.
Created Dimension and Fact Tables:
location_dim
date_dim
aqi_fact
Aggregate tables for analysis:
agg_city_fact_hour_level
agg_city_fact_day_level

4ï¸âƒ£ Visualization Layer:
Streamlit App connects directly to Snowflake.
Dropdown selectors for State â†’ City â†’ Station â†’ Date.
Visualizations:
ğŸ“ˆ Hourly AQI line chart
ğŸ“Š Pollutant-level stacked bar chart
ğŸ—ºï¸ Station geolocation map

5ï¸âƒ£ Automation Layer:
GitHub Actions Workflow triggers Python ingestion script hourly.
Ensures the pipeline runs automatically without manual intervention.


âš™ï¸ Tech Stack
Category	Tools / Services
Data Warehouse	ğŸ§Š Snowflake
Data Transformation	Snowflake Dynamic Tables
Scheduling	GitHub Actions
Data Ingestion	Python + Snowflake Connector
Visualization	Streamlit
Data Source	Government of India Open Data Portal (API)


ğŸ“Š Key Features
âœ… End-to-end ELT pipeline with automated hourly updates.
âœ… Real-time AQI computation at station, city, and state levels.
âœ… Full data lineage from API â†’ Stage â†’ Clean â†’ Consumption â†’ Dashboard.
âœ… No manual refresh â€” powered by Dynamic Tables + GitHub Actions.
âœ… Clean schema design with dimension and fact modeling.
âœ… Interactive dashboard to visualize and explore air quality trends.


ğŸ“‚ Repository Structure
ğŸ“ india-aqi-snowflake-project
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ§© aqi_ingest.py           # Python script for API data ingestion
â”œâ”€â”€ ğŸ§  snowflake_scripts/
â”‚   â”œâ”€â”€ create_db_schemas.sql
â”‚   â”œâ”€â”€ create_dynamic_tables.sql
â”‚   â”œâ”€â”€ create_tasks.sql
â”‚   â””â”€â”€ create_dimensions_facts.sql
â”œâ”€â”€ ğŸ§° .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ aqi_ingestion.yml  # GitHub Actions workflow
â”œâ”€â”€ ğŸ“Š streamlit_app/
â”‚   â”œâ”€â”€ app.py                 # Streamlit dashboard code
â”‚   â””â”€â”€ utils.py
â””â”€â”€ ğŸ–¼ï¸ dashboard_screenshot.png


ğŸ“ˆ Dashboard Preview
ğŸš€ Future Enhancements
Add historical AQI trend analysis for year-over-year comparison.
Integrate alerts/notifications for critical pollution levels.
Enable multi-region data visualization for different states.
Deploy Streamlit app on Streamlit Cloud or AWS EC2 for public access.


ğŸ’¡ Key Learnings
Hands-on experience with Snowflake Dynamic Tables for incremental transformations.
Building modular ETL pipelines using Python + Snowflake Tasks.
Automating workflows using GitHub Actions.
Designing dim-fact schemas for real-time data models.
End-to-end ownership: ingestion, transformation, automation, and visualization.
